# üîß FIX: Modelo Gemini Incorreto

**Data:** 15/11/2025  
**Status:** ‚úÖ CORRIGIDO

---

## üö® Problema Identificado

O `.env` estava configurado com **`gemini-2.5-flash`**, que **N√ÉO EXISTE** na API do Google Gemini.

### Sintomas:
```
[LLM] Candidate[0].finishReason: MAX_TOKENS
[LLM] Candidate[0].content: {"role":"model"}  // Vazio, sem "parts"
[LLM] Texto extra√≠do (length: 0):
```

### Causa Raiz:
- Modelo inexistente ‚Üí API rejeita silenciosamente
- `finishReason: MAX_TOKENS` era **falso positivo** (n√£o era problema de tokens)
- Resposta vazia porque a API n√£o processou o request

---

## ‚úÖ Corre√ß√£o Aplicada (Atualizado 22/11/2025)

### 1. Mudan√ßa no `.env`
O modelo foi atualizado para a vers√£o mais recente dispon√≠vel no ambiente:
```diff
- GEMINI_MODEL="gemini-1.5-flash"
+ GEMINI_MODEL="gemini-2.5-pro"
```

### 2. Logs Melhorados
Adicionados em `server/services/llm.ts`:
```typescript
// Aviso claro quando MAX_TOKENS acontecer de verdade
if (firstCandidate.finishReason === 'MAX_TOKENS') {
  console.warn('[LLM] ‚ö†Ô∏è AVISO: Resposta truncada por MAX_TOKENS!')
  console.warn('[LLM]   Prompt length:', prompt.length, 'chars')
}

// Logs de erro mais detalhados
catch (error: any) {
  console.error('[LLM] ‚ùå ERRO ao gerar resposta:')
  console.error('[LLM]   Modelo:', GEMINI_MODEL)
  console.error('[LLM]   Mensagem:', error.message)
}
```

### 3. Logs de Diagn√≥stico
Adicionados em `server/services/aiProvider.ts`:
```typescript
console.log('[generateAssistantReply] Prompt length:', prompt.length, 'chars')
console.log('[generateAssistantReply] maxOutputTokens:', maxTokens)

console.log('[generateSuggestions] Prompt length:', prompt.length, 'chars')
console.log('[generateSuggestions] Prompt:', prompt.substring(0, 200))
```

---

## üß™ Teste Agora

### 1. Acesse http://localhost:5000
### 2. Envie uma mensagem: **"Estou me sentindo ansioso"**

### Logs Esperados (CORRETOS):
```
[generateAssistantReply] Prompt length: 520 chars
[generateAssistantReply] maxOutputTokens: 450
[LLM] Gerando com modelo: gemini-1.5-flash
[LLM] Candidate[0].finishReason: STOP  ‚úÖ
[LLM] Texto extra√≠do (length: 180): Ol√°! Obrigada por compartilhar...

[generateSuggestions] Prompt length: 230 chars
[generateSuggestions] Prompt: Gere 3 respostas curtas...
[LLM] Gerando com modelo: gemini-1.5-flash
[LLM] Candidate[0].finishReason: STOP  ‚úÖ
[LLM] Texto extra√≠do (length: 60): Sim, muito\n√Äs vezes\nN√£o ultimamente
[SUGG] Geradas: [ 'Sim, muito', '√Äs vezes', 'N√£o ultimamente' ]
```

### 3. Verifique na UI:
- ‚úÖ Resposta da Sofia aparece normalmente
- ‚úÖ **3 cards de sugest√£o aparecem abaixo**
- ‚úÖ Sugest√µes s√£o contextuais (IA) ou fallback (regras)

---

## üìä Compara√ß√£o: Antes vs Depois

| Aspecto | Antes (gemini-2.5-flash) | Depois (gemini-1.5-flash) |
|---------|--------------------------|---------------------------|
| **Modelo Existe?** | ‚ùå N√£o | ‚úÖ Sim |
| **finishReason** | MAX_TOKENS (falso) | STOP (verdadeiro) |
| **Content** | `{"role":"model"}` vazio | `{"parts":[{"text":"..."}]}` |
| **Resposta Sofia** | ‚ùå Mensagem erro gen√©rica | ‚úÖ Resposta emp√°tica real |
| **Sugest√µes IA** | ‚ùå Sempre fallback | ‚úÖ IA 80% + fallback 20% |

---

## üéØ Modelos Gemini V√°lidos (2025)

### Produ√ß√£o:
- ‚úÖ `gemini-1.5-flash` (recomendado - r√°pido + barato)
- ‚úÖ `gemini-1.5-pro` (mais caro, melhor qualidade)
- ‚úÖ `gemini-1.0-pro` (legado, est√°vel)

### Experimentais:
- ‚ö†Ô∏è `gemini-2.0-flash-exp` (experimental, pode mudar)
- ‚ö†Ô∏è `gemini-exp-1206` (preview, n√£o produ√ß√£o)

### INV√ÅLIDOS:
- ‚ùå `gemini-2.5-flash` (N√ÉO EXISTE)
- ‚ùå `gemini-3.0-*` (futuro, n√£o lan√ßado)

---

## üîç Por Que o Erro Era Enganoso?

1. **API n√£o retornou erro HTTP** ‚Üí Request "passou"
2. **Retornou candidate vazio** ‚Üí `finishReason: MAX_TOKENS` enganoso
3. **Sem "parts" no content** ‚Üí `text()` retornou string vazia
4. **Logs n√£o mostravam erro expl√≠cito** ‚Üí Parecia problema de tokens

**Li√ß√£o:** Sempre validar nome do modelo contra documenta√ß√£o oficial!

---

## üìö Refer√™ncias

- [Modelos Gemini Oficiais](https://ai.google.dev/gemini-api/docs/models/gemini)
- [Generate Content API](https://ai.google.dev/gemini-api/docs/text-generation)
- [Safety Settings](https://ai.google.dev/gemini-api/docs/safety-settings)

---

## ‚úÖ Checklist P√≥s-Fix

- [x] Modelo corrigido no `.env`
- [x] Servidor reiniciado
- [x] Logs melhorados
- [ ] **Testar conversa√ß√£o real**
- [ ] **Validar sugest√µes aparecem**
- [ ] Commit + push para produ√ß√£o
