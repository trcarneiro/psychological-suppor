# üïµÔ∏è Auditoria T√©cnica e Plano de Melhorias - Psychological Support Platform

**Data:** 23/11/2025
**Status:** P√≥s-Corre√ß√£o de Crise (API Leak & Vercel Deploy)
**Vers√£o:** 0.0.0 (Alpha)

---

## üö® 1. Seguran√ßa (Prioridade Cr√≠tica)

### Diagn√≥stico
O projeto sofreu recentemente um vazamento de chave de API (`GEMINI_API_KEY`) devido a scripts de teste com credenciais "hardcoded". Embora corrigido, o sistema ainda apresenta vulnerabilidades estruturais.

### Problemas Identificados
*   **Scripts de Teste:** Scripts na pasta `scripts/` n√£o tinham verifica√ß√£o de ambiente segura (Corrigido, mas requer vigil√¢ncia).
*   **Autentica√ß√£o Permissiva:** O middleware `requireAuth` permite acesso irrestrito (`admin-dev`) se as vari√°veis do Supabase n√£o estiverem configuradas. Em produ√ß√£o, se essas vari√°veis falharem, o painel administrativo fica aberto.
*   **CORS:** Atualmente configurado como `origin: '*'` para resolver problemas de conex√£o. Isso permite que qualquer site fa√ßa requisi√ß√µes para sua API.

### Recomenda√ß√µes
1.  **[CR√çTICO] Bloqueio de Fallback de Auth:** Alterar `server/middleware/auth.ts` para **bloquear** o acesso por padr√£o em produ√ß√£o se o Supabase n√£o estiver configurado, em vez de liberar acesso admin.
2.  **[ALTA] Restri√ß√£o de CORS:** Configurar `origin` no CORS para aceitar apenas o dom√≠nio de produ√ß√£o do Vercel e `localhost` em desenvolvimento.
3.  **[M√âDIA] Rate Limiting:** Implementar `express-rate-limit` nas rotas `/api/messages` para evitar que bots consumam sua cota da API do Gemini, gerando custos ou bloqueios.

---

## üß† 2. Intelig√™ncia Artificial & LLM

### Diagn√≥stico
O uso do modelo `gemini-2.5-pro` (Thinking Model) trouxe qualidade, mas introduziu lat√™ncia alta e consumo massivo de tokens de "pensamento" (1600+ tokens antes de responder).

### Problemas Identificados
*   **Lat√™ncia Percebida:** O usu√°rio v√™ "Digitando..." por 5-10 segundos enquanto o modelo "pensa". Isso causa ansiedade em um app de suporte psicol√≥gico.
*   **Consumo de Tokens:** O limite foi aumentado para 4096, mas isso n√£o resolve o custo/tempo.
*   **Contexto Infinito:** O hist√≥rico da conversa √© enviado integralmente a cada mensagem. Conversas longas ficar√£o lentas e atingir√£o o limite do modelo rapidamente.

### Recomenda√ß√µes
1.  **[ALTA] Streaming de Resposta:** Implementar respostas via *stream* (texto aparecendo letra por letra). Isso √© vital para UX em modelos lentos como o "Thinking", pois d√° feedback imediato ao usu√°rio.
2.  **[M√âDIA] Janela de Contexto Deslizante:** Enviar apenas as √∫ltimas 10-15 mensagens para a API, ou implementar um mecanismo de "resumo" de conversas antigas para manter o contexto sem estourar tokens.
3.  **[BAIXA] Fallback de Modelo:** Ter um fallback autom√°tico para `gemini-1.5-flash` (muito mais r√°pido e barato) caso o `pro` falhe ou demore demais.

---

## üèóÔ∏è 3. Arquitetura & C√≥digo

### Diagn√≥stico
O projeto usa uma arquitetura h√≠brida (Vite SPA + Express Backend) adaptada para Vercel Serverless. A estrutura atual √© funcional mas fr√°gil.

### Problemas Identificados
*   **Roteamento Manual:** O `App.tsx` usa um `useState` (`viewMode`) para navega√ß√£o. Isso quebra o bot√£o "Voltar" do navegador e impede links diretos para p√°ginas (ex: `/blog/artigo-1`).
*   **Bundle Size:** O build acusou chunks > 500kB. O `App.tsx` importa todos os componentes (`Dashboard`, `AdminLogin`) de uma vez, pesando o carregamento inicial.
*   **Tipagem:** Uso de `@ts-ignore` em pontos cr√≠ticos de autentica√ß√£o.

### Recomenda√ß√µes
1.  **[ALTA] Code Splitting (Lazy Loading):** Usar `React.lazy` e `Suspense` para carregar `Dashboard` e `AdminLogin` apenas quando necess√°rios. Isso vai reduzir drasticamente o tempo de carregamento inicial.
2.  **[M√âDIA] React Router:** Migrar o `viewMode` para `react-router-dom`. Isso habilitar√° URLs reais, hist√≥rico do navegador e melhor SEO para o blog.
3.  **[BAIXA] Estrutura de Pastas:** Mover `server/` para fora ou usar um framework fullstack como Next.js ou Remix no futuro para evitar a "gambiarra" de adapta√ß√£o do Express para Serverless.

---

## üé® 4. UX/UI & Acessibilidade

### Diagn√≥stico
A interface √© limpa, mas carece de feedback de estado robusto.

### Problemas Identificados
*   **Feedback de Erro:** Erros de API (como o 500 recente) aparecem apenas no console ou travam o chat. O usu√°rio n√£o sabe o que aconteceu.
*   **Mobile:** O teclado virtual em celulares pode cobrir o campo de input se n√£o houver tratamento de viewport.

### Recomenda√ß√µes
1.  **[ALTA] Toasts de Erro:** Exibir mensagens amig√°veis ("N√£o foi poss√≠vel conectar. Tente novamente.") usando o componente `Sonner` j√° instalado.
2.  **[M√âDIA] Indicador de "Pensando":** Diferenciar "Digitando..." (gerando texto) de "Pensando..." (processamento do modelo Thinking) para gerenciar a expectativa do usu√°rio.

---

## üöÄ 5. DevOps & Deploy

### Diagn√≥stico
O processo de deploy depende de commits manuais e "tentativa e erro" no Vercel.

### Problemas Identificados
*   **Vari√°veis de Ambiente:** Depend√™ncia cr√≠tica de configura√ß√£o manual no painel do Vercel.
*   **Logs:** Logs de produ√ß√£o s√£o dif√≠ceis de acessar/ler no Vercel (apenas console output).

### Recomenda√ß√µes
1.  **[M√âDIA] Valida√ß√£o de ENV:** Criar um script `check-env.ts` que roda no `prebuild` e falha o build se vari√°veis cr√≠ticas (`DATABASE_URL`, `GEMINI_API_KEY`) estiverem faltando.
2.  **[BAIXA] Monitoramento:** Integrar com Sentry ou similar para rastrear erros de frontend/backend em tempo real.

---

## üìã Plano de A√ß√£o Imediato (Sugest√£o)

1.  **Hoje:** Implementar **Lazy Loading** no `App.tsx` para resolver o aviso de bundle size e melhorar performance.
2.  **Hoje:** Refor√ßar a seguran√ßa do **CORS** e **Auth** para evitar novos vazamentos ou acessos indevidos.
3.  **Amanh√£:** Implementar **Streaming** na resposta do chat (complexidade m√©dia, alto impacto).

Deseja que eu comece por algum desses itens?
